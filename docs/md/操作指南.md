#  操作指南
## <a id="project">项目管理</a>
#### 前提条件
创建项目需要指定计算引擎，若还没有计算引擎，请参考 [引擎管理](#engine) 创建该项目的计算引擎。
#### 创建项目
在 赤兔实时计算平台 中选择 **项目管理** > **新建项目**，在弹窗中填写项目名称、项目编码、选择计算引擎等，单击确定后即可在项目列表中看到新建的项目。

![输入图片说明](image/ops_img/新建项目.png)
#### 项目编辑、项目删除、添加项目成员
![输入图片说明](image/ops_img/项目管理.png)

## 作业开发
#### 前提条件
新增作业需要在项目下面，若还没有项目工程，请参考 [项目管理](#project) 创建该项目工程。

#### 进入作业开发页面
![输入图片说明](image/ops_img/进入作业1.png)
![输入图片说明](image/ops_img/进入作业2.png)

#### 新增SQL作业
在 赤兔实时计算平台  中选择 **实时开发** > **作业开发** > **新建**，在弹窗中填写作业名称、选择作业等级和作业类型等，单击确定后即可。

![输入图片说明](image/ops_img/新增作业.png)

新增元表
![输入图片说明](image/ops_img/新增元表.png)

编写 SQL
![输入图片说明](image/ops_img/编写sql.png)

SQL 验证与作业发布,发布之后,需要到 **作业运维** 中启动作业。
![输入图片说明](image/ops_img/sql验证.png)

#### 新增DS作业
首先需要在 **资源管理** 中，上传用户开发的 Flink DataStream JAR 包。
然后选择 **实时开发** > **作业开发** > **新建**，在弹窗中填写作业名称、选择作业等级和作业类型为DS、选择JAR包等，单击确定后即可。

![输入图片说明](image/ops_img/新增作业ds.png)

作业发布,发布之后,需要到 **作业运维** 中启动作业。
![输入图片说明](image/ops_img/作业发布ds.png)

#### 高级配置
支持 Flink 高级参数自定义，需按照 YML 语法，并以“key: value”的形式进行配置。
![输入图片说明](image/ops_img/高级配置.png)

#### 资源配置
可以按需配置 JobManager 和 TaskManager 的内存大小、全局并发度，灵活运用资源。
![输入图片说明](image/ops_img/资源配置.png)

#### 版本信息
每次作业发布都会产生一个新的版本，使用版本管理可以对作业回滚历史版本，增加操作的容错率。
![输入图片说明](image/ops_img/版本信息.png)
![输入图片说明](image/ops_img/版本比较.png)

#### 基础信息
基础信息包括作业创建人、更新人以及作业状态等信息。
![输入图片说明](image/ops_img/基础信息.png)

## 作业运维
#### 作业管理
作业运维主要包括作业启动、停止、暂停、恢复、添加保存点等操作。
![输入图片说明](image/ops_img/作业运维.png)
#### 作业日志
作业产生的日志可以在**运行结果**里面找到**查看Yarn日志**查看或者点击列表中的**flink ui**查看。
![输入图片说明](image/ops_img/运行日志.png)
![输入图片说明](image/ops_img/flinkui日志.png)
#### 作业监控
可以给每个作业设置监控规则和阈值，达到阈值会触发告警。告警通过邮件、短信或者电话的方式通知。
![输入图片说明](image/ops_img/告警配置.png)

## 资源管理
用于上传flink自定义UDF、flink作业的jar包。在**实时开发**菜单栏的**资源管理**中新增jar包。
![3a93ad9c69ffe18faa4651721d7f926b.png](image/ops_img/资源管理1.png)


## 数据源管理
用于读取或者写入，在**实时开发**菜单栏的**数据源管理**中添加数据源，填写数据源信息后点击验证，验证通过即可添加。
![272b9e04576a6b50581e7ac2c1911246.png](image/ops_img/数据源管理.png)


## 实时作业流程
在**我的流程**菜单栏中**实时作业流程**中，用于查看作业开发完后进行上线的申请流程，以及需要审批的流程与审批操作。
![d1ea1aab1e4abe266c92e02b4ea4091d.png](image/ops_img/实时作业流程.png)




## 用户管理
对系统内的用户进行添加修改删除查看，其中邮箱可用于接收告警信息，在作业异常时会发告警信息给相关负责人。
![95431893663f0b85eafd0a0472dc5129.png](image/ops_img/用户管理1.png)

## 引擎管理
用于任务运行所用到的集群资源
### 创建集群配置
首先先要在配置文件中创建相应的集群配置信息，其中yarn配置信息如下
```
yarn:
    envMap:
        uat: #UAT环境
            defaultConfig:
                queue: sdp_flink #yarn队列
                container:
                    minVcores: 1 #容器最小核数
                    minMem: 2 #容器最小内存，单位G
            clusterSyncLocalDir: /app/bigdata-sdp/  #存放jar的相关资源本地路径
            clusters:
            - clusterName: uat赤兔独立集群 #集群名称
              clusterCode: one_ticket_cluster #集群code
              nameServices: hdfs://bigbigworld
              flinkClient114Url: http://10.121.18.1:12228 #submit项目部署节点
              flinkClient115Url: http://10.121.18.1:12229 #submit项目部署节点
              hadoopConfDir: /opt/apache/hadoop-one-ticket/etc/hadoop
              flinkProxyUrl:
              flinkHistoryUrl:
        prod: #生产环境
            defaultConfig:
            queue: sdp_flink
            container:
                minVcores: 1 #容器最小核数
                minMem: 2 #容器最小内存，单位G
            clusterSyncLocalDir: /app/bigdata-sdp/
            clusters:
            - clusterName: prod赤兔独立集群
              clusterCode: one_ticket_cluster
              nameServices: hdfs://bigbigworld
              flinkClient114Url: http://10.121.18.1:12228
              flinkClient115Url: http://10.121.18.1:12229
              hadoopConfDir: /opt/apache/hadoop-one-ticket/etc/hadoop
              flinkProxyUrl:
              flinkHistoryUrl:

```
其中k8s配置信息如下
```
kubernetes:
    #构建镜像等待时间
    buildImageTimeout: 300
    #任务启动后检测状态次数，每次等待5秒
    startMaxCheckNumber: 60
    #k8s日志高级搜索过滤字段
    logFilterField: kubernetes.pod.name
    # 镜像
    imagePrefix: flink-application-sdp-
    dockerFilePrefix: Dockerfile-
    sqlBaseImage: flink-application-sdp-sql-client
    flinkUserJarPrefix: local:///opt/flink/usrlib/
    sql114Jar: bigdata-sdp-flink-sqlclient-1.14-1.0.0-SNAPSHOT.jar
    sql115Jar: bigdata-sdp-flink-sqlclient-1.15-1.0.0-SNAPSHOT.jar
    hadoopConfigMapName: hadoop-sdp
    jobManagerServiceAccount: flink-service-account
    envMap:
        uat:
            clusters:
                - clusterName: uat_kubernetes测试集群
                  clusterCode: kubernetes_test_uat
                  flinkClient114Url: http://10.121.18.1:12228
                  flinkClient115Url: http://10.121.18.1:12229
                  hadoopConfDir: /opt/apache/hadoop-one-ticket/etc/hadoop
                  dockerFileWorkspace: /data/sdp/uat
                  dockerHubAddress: bigdata-uat-k8s-harbor.ky-tech.com.cn/bigdata-flink/
                  caCertData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1EWXhOekV4TWpRek1sb1hEVE15TURZeE5ERXh==
                  clientCertData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJTmFTTndyL3Y5OUV3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TWpBMk1UY3hNVEkwTXpKYUZ3MHlNekEyTVRjeE1USTBNelJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQ==
                  clientKeyData: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBdVZJd1lOQUh0SXdHbzRuYkJQUURlQlp0NnBkdHh5eGNyN29mcDZueHJ2eXJtN2VRCko5YmlLbjNFb0oxNU9NOHoxRWk1Q2VLMS8yODhuZFV5MFYzMmdHUkJPVGc4eDJFSFFYL01TSVRMbnBwNmZzTTAKek1FMHV6eW0xU0RkeEw0ZGpmUjJXQTk1eEJJeWVyb0tKR1ZV==
                  masterUrl: https://10.83.192.110:6443
                  namespaces:
                  - hadoop-test-ha
                  - hadoop-test-ha2
        prod:
            clusters:
              - clusterName: uat kubernetes测试集群
                clusterCode: kubernetes_test
                flinkClient114Url: http://10.121.18.1:12228
                flinkClient115Url: http://10.121.18.1:12229
                hadoopConfDir: /opt/apache/hadoop-one-ticket/etc/hadoop
                dockerFileWorkspace: /data/sdp/prod
                dockerHubAddress: bigdata-uat-k8s-harbor.ky-tech.com.cn/bigdata-flink/
                caCertData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1EWXhOekV4TWpRek1sb1hEVE15TURZeE5ERXhNalF6TWxvd0ZU==
                clientCertData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJTmFTTndyL3Y5OUV3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TWpBMk1UY3hNVEkwTXpKYUZ3MHlNekEyTVRjeE1==
                clientKeyData: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBdVZJd1lOQUh0SXdHbzRuYkJQUURlQlp0NnBkdHh5eGNyN29mcDZueHJ2eXJtN2VRCko5YmlLbjNFb0oxNU9NOHoxRWk1Q2VLMS8yODhuZFV5MFYzMmdHUkJPVGc4eDJ==
                masterUrl: https://10.83.192.110:6443
                namespaces:
                - hadoop-test-ha

```
配置完之后配置就可以在引擎管理添加相应的引擎了
![560792e5dac4c6f847bd9c24ce95b993.png](image/ops_img/引擎管理1.png)

## 实时系统设置
一些系统设置，**可执行状态**可以让用户没有对应的操作权限，**开启资源验证**用于启动作业时验证资源是否充足，**规则告警定时任务开关**用于开启或者关闭规则告警事件，**是否需要二级审批**用于作业上线时的审批流程，如果选择OFF只需要一级审批。
![e3ba64712e03a52b4be708ee0c75c0ab.png](image/ops_img/实时系统设置.png)

## 其他配置

### 告警通知邮箱配置
其中告警通知消息使用邮箱接收，可自行改造消息通知入口添加其他通知渠道。


登录网易邮箱(或者其他服务商)设置第三方授权码，开启POP/IMAP等协议，然后在配置文件配置对应的授权码即可。
![6b1fec89d6f4a69cddcaa43d66ac5416.png](image/ops_img/邮箱配置.png)
